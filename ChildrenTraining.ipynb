{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUrWuT5Jz1eB"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28KySsAR0Zck",
        "outputId": "9ce37bfc-6560-46cc-98d2-ebd6ebe8d65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMP_NdgRz6MR"
      },
      "source": [
        "# Setup training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyOHf9BLN0dq",
        "outputId": "82060515-4f55-45dc-eb33-bfd350c90f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Lazimpa'...\n",
            "remote: Enumerating objects: 2453, done.\u001b[K\n",
            "remote: Total 2453 (delta 0), reused 0 (delta 0), pack-reused 2453\u001b[K\n",
            "Receiving objects: 100% (2453/2453), 39.15 MiB | 11.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1530/1530), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "! git clone https://github.com/Daetheys/Lazimpa.git\n",
        "! mv \"./Lazimpa/egg\" \"./egg\"\n",
        "! mv \"./Lazimpa/example\" \"./example\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5qjFdU4caPN"
      },
      "outputs": [],
      "source": [
        "! mkdir -p dir_save/{accuracy,messages,sender,receiver}\n",
        "! mkdir analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVPFp7cbkdop",
        "outputId": "911954a0-64bc-4c60-bfb8-b82cebc7e052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLPMVA'...\n",
            "remote: Enumerating objects: 181, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 181 (delta 0), reused 1 (delta 0), pack-reused 178\u001b[K\n",
            "Receiving objects: 100% (181/181), 287.11 MiB | 12.18 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "Checking out files: 100% (82/82), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Daetheys/NLPMVA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlBJZf866mJ8"
      },
      "source": [
        "# Distribution generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuAel3U6klwY",
        "outputId": "b679053a-8003-4ed9-a483-9caa69cd0967"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import numpy as np\n",
        "distribution = []\n",
        "with open('NLPMVA/distribution (corrected).txt') as f:\n",
        "    try:\n",
        "        while True:\n",
        "            data = f.readline()\n",
        "            distribution.append(eval(data))\n",
        "    except SyntaxError:\n",
        "        pass\n",
        "distribution_proba = np.array([d[1] for d in distribution])\n",
        "distribution_lbl = np.array([d[0] for d in distribution])\n",
        "distribution_lbl.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUSEeorNNnW1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "import itertools\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import egg.core as core\n",
        "#from scipy.stats import entropy\n",
        "from egg.core import EarlyStopperAccuracy\n",
        "from egg.zoo.channel.features import OneHotLoader, UniformLoader, OneHotLoaderCompositionality, TestLoaderCompositionality\n",
        "from egg.zoo.channel.archs import Sender, Receiver\n",
        "from egg.core.reinforce_wrappers import RnnReceiverImpatient, RnnReceiverImpatientCompositionality, RnnReceiverCompositionality\n",
        "from egg.core.reinforce_wrappers import SenderImpatientReceiverRnnReinforce, CompositionalitySenderImpatientReceiverRnnReinforce, CompositionalitySenderReceiverRnnReinforce\n",
        "from egg.core.util import dump_sender_receiver_impatient, dump_sender_receiver_impatient_compositionality, dump_sender_receiver_compositionality\n",
        "\n",
        "from egg.core.trainers import CompoTrainer\n",
        "from egg.zoo.channel.train_compositionality import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw7Wtmgm9G4w"
      },
      "outputs": [],
      "source": [
        "class _DistributionIterator:\n",
        "    \"\"\"\n",
        "    >>> it_1 = _OneHotIterator(n_features=128, n_batches_per_epoch=2, batch_size=64, probs=np.ones(128)/128, seed=1)\n",
        "    >>> it_2 = _OneHotIterator(n_features=128, n_batches_per_epoch=2, batch_size=64, probs=np.ones(128)/128, seed=1)\n",
        "    >>> list(it_1)[0][0].allclose(list(it_2)[0][0])\n",
        "    True\n",
        "    >>> it = _OneHotIterator(n_features=8, n_batches_per_epoch=1, batch_size=4, probs=np.ones(8)/8)\n",
        "    >>> data = list(it)\n",
        "    >>> len(data)\n",
        "    1\n",
        "    >>> batch = data[0]\n",
        "    >>> x, y = batch\n",
        "    >>> x.size()\n",
        "    torch.Size([4, 8])\n",
        "    >>> x.sum(dim=1)\n",
        "    tensor([1., 1., 1., 1.])\n",
        "    >>> probs = np.zeros(128)\n",
        "    >>> probs[0] = probs[1] = 0.5\n",
        "    >>> it = _OneHotIterator(n_features=128, n_batches_per_epoch=1, batch_size=256, probs=probs, seed=1)\n",
        "    >>> batch = list(it)[0][0]\n",
        "    >>> batch[:, 0:2].sum().item()\n",
        "    256.0\n",
        "    >>> batch[:, 2:].sum().item()\n",
        "    0.0\n",
        "    \"\"\"\n",
        "    def __init__(self, n_features, n_batches_per_epoch, batch_size, seed=None):\n",
        "        self.n_batches_per_epoch = n_batches_per_epoch\n",
        "        self.n_features = n_features\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.batches_generated = 0\n",
        "        self.random_state = np.random.RandomState(seed)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.batches_generated >= self.n_batches_per_epoch:\n",
        "            raise StopIteration()\n",
        "\n",
        "        idxs = np.random.choice(len(distribution),self.batch_size,p=distribution_proba)\n",
        "        batch_data = np.zeros((self.batch_size,self.n_features*2,))\n",
        "        \n",
        "        for i in range(distribution_lbl.shape[1]):\n",
        "            batch_data[np.arange(self.batch_size),distribution_lbl[idxs,i]+i*self.n_features] = 1\n",
        "\n",
        "        self.batches_generated += 1\n",
        "        return torch.from_numpy(batch_data).float(), torch.zeros(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuzdgIUX89bX"
      },
      "outputs": [],
      "source": [
        "class DistributionLoader(torch.utils.data.DataLoader):\n",
        "    \"\"\"\n",
        "    >>> probs = np.ones(8) / 8\n",
        "    >>> data_loader = OneHotLoader(n_features=8, batches_per_epoch=3, batch_size=2, probs=probs, seed=1)\n",
        "    >>> epoch_1 = []\n",
        "    >>> for batch in data_loader:\n",
        "    ...     epoch_1.append(batch)\n",
        "    >>> [b[0].size() for b in epoch_1]\n",
        "    [torch.Size([2, 8]), torch.Size([2, 8]), torch.Size([2, 8])]\n",
        "    >>> data_loader_other = OneHotLoader(n_features=8, batches_per_epoch=3, batch_size=2, probs=probs)\n",
        "    >>> all_equal = True\n",
        "    >>> for a, b in zip(data_loader, data_loader_other):\n",
        "    ...     all_equal = all_equal and (a[0] == b[0]).all()\n",
        "    >>> all_equal.item()\n",
        "    0\n",
        "    \"\"\"\n",
        "    def __init__(self, n_features, batches_per_epoch, batch_size, seed=None):\n",
        "        self.seed = seed\n",
        "        self.batches_per_epoch = batches_per_epoch\n",
        "        self.n_features = n_features\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.seed is None:\n",
        "            seed = np.random.randint(0, 2 ** 32)\n",
        "        else:\n",
        "            seed = self.seed\n",
        "\n",
        "        return _DistributionIterator(n_features=self.n_features, n_batches_per_epoch=self.batches_per_epoch,\n",
        "                               batch_size=self.batch_size,  seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4uxW2Jk9ntt"
      },
      "outputs": [],
      "source": [
        "class DistributionUniformLoader(torch.utils.data.DataLoader):\n",
        "    def __init__(self, n_features):\n",
        "        idxs = np.arange(len(distribution))\n",
        "        batch_data = np.zeros((len(distribution),n_features*2,))\n",
        "        \n",
        "        for i in range(distribution_lbl.shape[1]):\n",
        "            batch_data[np.arange(len(distribution)),distribution_lbl[idxs,i]+i*n_features] = 1\n",
        "\n",
        "        self.batch = torch.from_numpy(batch_data).float(), torch.zeros(1)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter([self.batch])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLP5u8MIz39y"
      },
      "source": [
        "#Define parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPrPgQwYKqB6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import torch\n",
        "class Config:\n",
        "\n",
        "    #IMPORTANT PARAMETERS\n",
        "    impatient = False #Impatient Listener\n",
        "    reg = False #Lazy Speaker\n",
        "    random_seed = np.random.randint(0,100) #Seed used for the training\n",
        "    lr = 3e-4 #Learning rate of both neural networks\n",
        "    batch_size = 512 #Batch size for the training\n",
        "    n_epochs = 101 #Nb of epochs for the training\n",
        "    batches_per_epoch = 10 #Nb of batch per epoch\n",
        "\n",
        "    vocab_size = 100 #Number of words in the speaker's vocabulary\n",
        "    max_len = 2 #Maximum number of words the speaker can use to describe the combination of concepts given as input\n",
        "    n_values = 100 #Nb of different concepts\n",
        "    n_attributes = 2 #Nb of concepts that will be combined (and need to be guessed at the same time)\n",
        "\n",
        "    custom_dist = False #Use Eva's distribution instead of the one of the paper\n",
        "\n",
        "    checkpoint_path = \"NLPMVA/trainingscompo\"\n",
        "    nb_children_per_language = 3\n",
        "\n",
        "    #Eva's parameters\n",
        "    if custom_dist:\n",
        "        n_values = distribution_lbl.max()+1\n",
        "        n_attributes = 2\n",
        "\n",
        "        vocab_size = n_values\n",
        "        max_len = 2\n",
        "\n",
        "    #LESS IMPORTANT PARAMETERS\n",
        "    n_features = 100\n",
        "\n",
        "    receiver_hidden = 450\n",
        "    receiver_num_layers = 1\n",
        "    receiver_num_heads = 1\n",
        "    receiver_embedding = 100\n",
        "    receiver_cell = 'gru'\n",
        "    receiver_entropy_coeff = 0.1\n",
        "\n",
        "    sender_hidden = 600\n",
        "    sender_num_layers = 1\n",
        "    sender_num_heads = 1\n",
        "    sender_embedding = 100\n",
        "    sender_cell = 'gru'\n",
        "    sender_entropy_coeff = 0.4\n",
        "\n",
        "    length_cost = 0.\n",
        "    name = 'model'\n",
        "    early_stopping_thr = 0.99\n",
        "\n",
        "    dir_save = 'dir_save'#'expe_'+str(time.time()).split('.')[0]\n",
        "    checkpoint_dir = None#os.path.join('expe_'+str(time.time()).split('.')[0],'checkpoint')\n",
        "\n",
        "    unigram_pen = 0.\n",
        "\n",
        "    force_eos = False\n",
        "\n",
        "    optimizer_class = torch.optim.Adam\n",
        "    validation_freq = 1\n",
        "    device = 'cuda:0'\n",
        "\n",
        "    load_from_checkpoint = None\n",
        "    checkpoint_freq = 0\n",
        "    preemptable = False\n",
        "\n",
        "    probs = 'uniform'\n",
        "    probs_attributes = 'uniform'\n",
        "\n",
        "    att_weights = [1,1,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w2khG5Q2vkr"
      },
      "source": [
        "# Dump compo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBduJAj-9K2S"
      },
      "outputs": [],
      "source": [
        "def dump_compositionality(game, n_attributes, n_values, device, gs_mode,epoch):\n",
        "    one_hots = torch.eye(n_values)\n",
        "\n",
        "    val=np.arange(n_values)\n",
        "    combination=list(itertools.product(val,repeat=n_attributes))\n",
        "\n",
        "    dataset=[]\n",
        "\n",
        "    for i in range(len(combination)):\n",
        "      new_input=torch.zeros(0)\n",
        "      for j in combination[i]:\n",
        "        new_input=torch.cat((new_input,one_hots[j]))\n",
        "      dataset.append(new_input)\n",
        "\n",
        "    dataset=torch.stack(dataset)\n",
        "\n",
        "    dataset=[[dataset,None]]\n",
        "\n",
        "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
        "        dump_sender_receiver_compositionality(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
        "\n",
        "    unif_acc = 0.\n",
        "    acc_vec=np.zeros(((n_values**n_attributes), n_attributes))\n",
        "\n",
        "    for i in range(len(receiver_outputs)):\n",
        "      message=messages[i]\n",
        "      correct=True\n",
        "      if i<n_values**n_attributes:\n",
        "          for j in range(len(list(combination[i]))):\n",
        "            if receiver_outputs[i][j]==list(combination[i])[j]:\n",
        "              unif_acc+=1\n",
        "              acc_vec[i,j]=1\n",
        "      #if i<5:\n",
        "      #    print(f'input: {\",\".join([str(x) for x in combination[i]])} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {\",\".join([str(x) for x in receiver_outputs[i]])}', flush=True)\n",
        "\n",
        "    unif_acc /= (n_values**n_attributes) * n_attributes\n",
        "\n",
        "    #print(json.dumps({'unif': unif_acc}))\n",
        "\n",
        "    return acc_vec, messages\n",
        "\n",
        "def custom_dump_compositionality(game, n_attributes, n_values, device, gs_mode,epoch):\n",
        "\n",
        "    dataset=DistributionUniformLoader(n_values)\n",
        "\n",
        "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
        "        dump_sender_receiver_compositionality(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
        "\n",
        "    unif_acc = 0.\n",
        "    acc_vec=np.zeros(((n_values**n_attributes), n_attributes))\n",
        "\n",
        "    for i in range(len(receiver_outputs)):\n",
        "      message=messages[i]\n",
        "      correct=True\n",
        "      if i<n_values**n_attributes:\n",
        "          for j in range(len(distribution_lbl[i])):\n",
        "            if receiver_outputs[i][j]==list(distribution_lbl[i])[j]:\n",
        "              unif_acc+=1\n",
        "              acc_vec[i,j]=1\n",
        "      #if i<5:\n",
        "      #    print(f'input: {\",\".join([str(x) for x in distribution_lbl[i]])} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {\",\".join([str(x) for x in receiver_outputs[i]])}', flush=True)\n",
        "\n",
        "    unif_acc /= (n_values**n_attributes) * n_attributes\n",
        "\n",
        "    #print(json.dumps({'unif': unif_acc}))\n",
        "\n",
        "    return acc_vec, messages\n",
        "\n",
        "def dump_impatient_compositionality(game, n_attributes, n_values, device, gs_mode,epoch):\n",
        "    # tiny \"dataset\"\n",
        "    one_hots = torch.eye(n_values)\n",
        "\n",
        "    val=np.arange(n_values)\n",
        "    combination=list(itertools.product(val,repeat=n_attributes))\n",
        "\n",
        "    dataset=[]\n",
        "\n",
        "    for i in range(len(combination)):\n",
        "      new_input=torch.zeros(0)\n",
        "      for j in combination[i]:\n",
        "        new_input=torch.cat((new_input,one_hots[j]))\n",
        "      dataset.append(new_input)\n",
        "\n",
        "    dataset=torch.stack(dataset)\n",
        "\n",
        "    dataset=[[dataset,None]]\n",
        "\n",
        "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
        "        dump_sender_receiver_impatient_compositionality(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
        "\n",
        "    unif_acc = 0.\n",
        "    acc_vec=np.zeros(((n_values**n_attributes), n_attributes))\n",
        "\n",
        "    for i in range(len(receiver_outputs)):\n",
        "      message=messages[i]\n",
        "      correct=True\n",
        "      for j in range(len(list(combination[i]))):\n",
        "        if receiver_outputs[i][j]==list(combination[i])[j]:\n",
        "          unif_acc+=1\n",
        "          acc_vec[i,j]=1\n",
        "      #if epoch%5==0 and i<5:\n",
        "      #    print(f'input: {\",\".join([str(x) for x in combination[i]])} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {\",\".join([str(x) for x in receiver_outputs[i]])}', flush=True)\n",
        "\n",
        "    unif_acc /= (n_values**n_attributes) * n_attributes\n",
        "\n",
        "    #print(json.dumps({'unif': unif_acc}))\n",
        "\n",
        "    return acc_vec, messages\n",
        "\n",
        "def custom_dump_impatient_compositionality(game, n_attributes, n_values, device, gs_mode,epoch):\n",
        "\n",
        "    dataset = DistributionUniformLoader(n_values)\n",
        "\n",
        "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
        "        dump_sender_receiver_impatient_compositionality(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
        "\n",
        "    unif_acc = 0.\n",
        "    acc_vec=np.zeros(((n_values**n_attributes), n_attributes))\n",
        "\n",
        "    for i in range(len(receiver_outputs)):\n",
        "      message=messages[i]\n",
        "      correct=True\n",
        "      for j in range(len(receiver_outputs[i])):\n",
        "        if receiver_outputs[i][j]==list(distribution_lbl[i])[j]:\n",
        "          unif_acc+=1\n",
        "          acc_vec[i,j]=1\n",
        "      #if epoch%5==0 and i<5:\n",
        "      #    print(f'input: {\",\".join([str(x) for x in distribution_lbl[i]])} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {\",\".join([str(x) for x in receiver_outputs[i]])}', flush=True)\n",
        "\n",
        "    unif_acc /= (n_values**n_attributes) * n_attributes\n",
        "\n",
        "    #print(json.dumps({'unif': unif_acc}))\n",
        "\n",
        "    return acc_vec, messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpFDy2Fw6prA"
      },
      "source": [
        "# Pipeline from the git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR6YsCh8OXhw"
      },
      "outputs": [],
      "source": [
        "def entropy_dict(freq_table):\n",
        "    H = 0\n",
        "    n = sum(v for v in freq_table.values())\n",
        "\n",
        "    for m, freq in freq_table.items():\n",
        "        p = freq_table[m] / n\n",
        "        H += -p * np.log(p)\n",
        "    return H / np.log(2)\n",
        "\n",
        "def _hashable_tensor(t):\n",
        "    if isinstance(t, tuple):\n",
        "        return t\n",
        "    if isinstance(t, int):\n",
        "        return t\n",
        "\n",
        "    try:\n",
        "        t = t.item()\n",
        "    except ValueError:\n",
        "        t = tuple(t.view(-1).tolist())\n",
        "    return t\n",
        "\n",
        "def entropy(messages):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    freq_table = defaultdict(float)\n",
        "\n",
        "    for m in messages:\n",
        "        m = _hashable_tensor(m)\n",
        "        freq_table[m] += 1.0\n",
        "\n",
        "    return entropy_dict(freq_table)\n",
        "\n",
        "def mutual_info(xs, ys):\n",
        "    e_x = entropy(xs)\n",
        "    e_y = entropy(ys)\n",
        "\n",
        "    xys = []\n",
        "\n",
        "    for x, y in zip(xs, ys):\n",
        "        xy = (_hashable_tensor(x), _hashable_tensor(y))\n",
        "        xys.append(xy)\n",
        "\n",
        "    e_xy = entropy(xys)\n",
        "\n",
        "    return e_x + e_y - e_xy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh7SuJepPpAZ"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict, Optional\n",
        "\n",
        "import torch\n",
        "\n",
        "from egg.core.util import move_to\n",
        "\n",
        "\n",
        "class Batch:\n",
        "    def __init__(\n",
        "        self,\n",
        "        sender_input: torch.Tensor,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        receiver_input: Optional[torch.Tensor] = None,\n",
        "        aux_input: Optional[Dict[Any, Any]] = None,\n",
        "    ):\n",
        "        self.sender_input = sender_input\n",
        "        self.labels = labels\n",
        "        self.receiver_input = receiver_input\n",
        "        self.aux_input = aux_input\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        >>> b = Batch(torch.Tensor([1]), torch.Tensor([2]), torch.Tensor([3]), {})\n",
        "        >>> b[0]\n",
        "        tensor([1.])\n",
        "        >>> b[1]\n",
        "        tensor([2.])\n",
        "        >>> b[2]\n",
        "        tensor([3.])\n",
        "        >>> b[3]\n",
        "        {}\n",
        "        >>> b[6]\n",
        "        Traceback (most recent call last):\n",
        "            ...\n",
        "        IndexError: Trying to access a wrong index in the batch\n",
        "        \"\"\"\n",
        "        if idx == 0:\n",
        "            return self.sender_input\n",
        "        elif idx == 1:\n",
        "            return self.labels\n",
        "        elif idx == 2:\n",
        "            return self.receiver_input\n",
        "        elif idx == 3:\n",
        "            return self.aux_input\n",
        "        else:\n",
        "            raise IndexError(\"Trying to access a wrong index in the batch\")\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        >>> _ = torch.manual_seed(111)\n",
        "        >>> sender_input = torch.rand(2, 2)\n",
        "        >>> labels = torch.rand(2, 2)\n",
        "        >>> batch = Batch(sender_input, labels)\n",
        "        >>> it = batch.__iter__()\n",
        "        >>> it_sender_input = next(it)\n",
        "        >>> torch.allclose(sender_input, it_sender_input)\n",
        "        True\n",
        "        >>> it_labels = next(it)\n",
        "        >>> torch.allclose(labels, it_labels)\n",
        "        True\n",
        "        \"\"\"\n",
        "        return iter(\n",
        "            [self.sender_input, self.labels, self.receiver_input, self.aux_input]\n",
        "        )\n",
        "\n",
        "    def to(self, device: torch.device):\n",
        "        \"\"\"Method to move all (nested) tensors of the batch to a specific device.\n",
        "        This operation doest not change the original batch element and returns a new Batch instance.\n",
        "        \"\"\"\n",
        "        self.sender_input = move_to(self.sender_input, device)\n",
        "        self.labels = move_to(self.labels, device)\n",
        "        self.receiver_input = move_to(self.receiver_input, device)\n",
        "        self.aux_input = move_to(self.aux_input, device)\n",
        "        return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u0NovWolKdH"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import torch\n",
        "from scipy import spatial\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "import egg.core as core\n",
        "\n",
        "try:\n",
        "    import editdistance  # package to install https://pypi.org/project/editdistance/0.3.1/\n",
        "except ImportError:\n",
        "    print(\n",
        "        \"Please install editdistance package: `pip install editdistance`. \"\n",
        "        \"It is used for calculating topographic similarity.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def ask_sender(n_attributes, n_values, dataset, sender, device):\n",
        "    attributes = []\n",
        "    strings = []\n",
        "    meanings = []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        meaning = dataset[i]\n",
        "\n",
        "        attribute = meaning.view(n_attributes, n_values).argmax(dim=-1)\n",
        "        attributes.append(attribute)\n",
        "        meanings.append(meaning.to(device))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            string, *other = sender(meaning.unsqueeze(0).to(device))\n",
        "        strings.append(string.squeeze(0))\n",
        "\n",
        "    attributes = torch.stack(attributes, dim=0)\n",
        "    strings = torch.stack(strings, dim=0)\n",
        "    meanings = torch.stack(meanings, dim=0)\n",
        "\n",
        "    return attributes, strings, meanings\n",
        "\n",
        "\n",
        "def information_gap_representation(meanings, representations):\n",
        "    gaps = torch.zeros(representations.size(1))\n",
        "    non_constant_positions = 0.0\n",
        "\n",
        "    for j in range(representations.size(1)):\n",
        "        symbol_mi = []\n",
        "        h_j = None\n",
        "        for i in range(meanings.size(1)):\n",
        "            x, y = meanings[:, i], representations[:, j]\n",
        "            info = mutual_info(x, y)\n",
        "            symbol_mi.append(info)\n",
        "\n",
        "            if h_j is None:\n",
        "                h_j = entropy(y)\n",
        "\n",
        "        symbol_mi.sort(reverse=True)\n",
        "\n",
        "        if h_j > 0.0:\n",
        "            gaps[j] = (symbol_mi[0] - symbol_mi[1]) / h_j\n",
        "            non_constant_positions += 1\n",
        "\n",
        "    score = gaps.sum() / non_constant_positions\n",
        "    return score.item()\n",
        "\n",
        "\n",
        "def information_gap_position(n_attributes, n_values, dataset, sender, device):\n",
        "    attributes, strings, _meanings = ask_sender(\n",
        "        n_attributes, n_values, dataset, sender, device\n",
        "    )\n",
        "    return information_gap_representation(attributes, strings)\n",
        "\n",
        "\n",
        "def histogram(strings, vocab_size):\n",
        "    batch_size = strings.size(0)\n",
        "\n",
        "    histogram = torch.zeros(batch_size, vocab_size, device=strings.device)\n",
        "\n",
        "    for v in range(vocab_size):\n",
        "        histogram[:, v] = strings.eq(v).sum(dim=-1)\n",
        "\n",
        "    return histogram\n",
        "\n",
        "\n",
        "def information_gap_vocab(n_attributes, n_values, dataset, sender, device, vocab_size):\n",
        "    attributes, strings, _meanings = ask_sender(\n",
        "        n_attributes, n_values, dataset, sender, device\n",
        "    )\n",
        "\n",
        "    histograms = histogram(strings, vocab_size)\n",
        "    return information_gap_representation(attributes, histograms[:, 1:])\n",
        "\n",
        "\n",
        "def edit_dist(_list):\n",
        "    distances = []\n",
        "    count = 0\n",
        "    for i, el1 in enumerate(_list[:-1]):\n",
        "        for j, el2 in enumerate(_list[i + 1 :]):\n",
        "            count += 1\n",
        "            # Normalized edit distance (same in our case as length is fixed)\n",
        "            distances.append(editdistance.eval(el1, el2) / len(el1))\n",
        "    return distances\n",
        "\n",
        "\n",
        "def cosine_dist(_list):\n",
        "    distances = []\n",
        "    for i, el1 in enumerate(_list[:-1]):\n",
        "        for j, el2 in enumerate(_list[i + 1 :]):\n",
        "            distances.append(spatial.distance.cosine(el1, el2))\n",
        "    return distances\n",
        "\n",
        "\n",
        "def topographic_similarity(n_attributes, n_values, dataset, sender, device):\n",
        "    _attributes, strings, meanings = ask_sender(\n",
        "        n_attributes, n_values, dataset, sender, device\n",
        "    )\n",
        "    list_string = []\n",
        "    for s in strings:\n",
        "        list_string.append([x.item() for x in s])\n",
        "    distance_messages = edit_dist(list_string)\n",
        "    distance_inputs = cosine_dist(meanings.cpu().numpy())\n",
        "\n",
        "    corr = spearmanr(distance_messages, distance_inputs).correlation\n",
        "    return corr\n",
        "\n",
        "\n",
        "class Metrics(core.Callback):\n",
        "    def __init__(self, dataset, device, n_attributes, n_values, vocab_size, freq=1):\n",
        "        self.dataset = dataset\n",
        "        self.device = device\n",
        "        self.n_attributes = n_attributes\n",
        "        self.n_values = n_values\n",
        "        self.epoch = 0\n",
        "        self.vocab_size = vocab_size\n",
        "        self.freq = freq\n",
        "\n",
        "    def dump_stats(self):\n",
        "        game = self.trainer.game\n",
        "        game.eval()\n",
        "\n",
        "        positional_disent = information_gap_position(\n",
        "            self.n_attributes, self.n_values, self.dataset, game.sender, self.device\n",
        "        )\n",
        "        bos_disent = information_gap_vocab(\n",
        "            self.n_attributes,\n",
        "            self.n_values,\n",
        "            self.dataset,\n",
        "            game.sender,\n",
        "            self.device,\n",
        "            self.vocab_size,\n",
        "        )\n",
        "        topo_sim = topographic_similarity(\n",
        "            self.n_attributes, self.n_values, self.dataset, game.sender, self.device\n",
        "        )\n",
        "\n",
        "        output = dict(\n",
        "            epoch=self.epoch,\n",
        "            positional_disent=positional_disent,\n",
        "            bag_of_symbol_disent=bos_disent,\n",
        "            topographic_sim=topo_sim,\n",
        "        )\n",
        "\n",
        "        output_json = json.dumps(output)\n",
        "        print(output_json, flush=True)\n",
        "\n",
        "        game.train()\n",
        "\n",
        "        return output\n",
        "\n",
        "    def on_train_end(self):\n",
        "        pass\n",
        "        #self.dump_stats()\n",
        "\n",
        "    def on_epoch_end(self, *stuff):\n",
        "        self.epoch += 1\n",
        "\n",
        "        if self.freq <= 0 or self.epoch % self.freq != 0:\n",
        "            return\n",
        "\n",
        "        self.dump_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucGSZirZ223H"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnyOYrLC6iHd"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "class HiddenPrints:\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHWtFn3KNoSA"
      },
      "outputs": [],
      "source": [
        "def train_config(opts):\n",
        "\n",
        "    import egg\n",
        "    egg.core.util.common_opts = opts\n",
        "    device = opts.device\n",
        "\n",
        "    force_eos = opts.force_eos == 1\n",
        "\n",
        "    # Distribution of the inputs\n",
        "    if opts.probs==\"uniform\":\n",
        "        probs=[]\n",
        "        probs_by_att = np.ones(opts.n_values)\n",
        "        probs_by_att /= probs_by_att.sum()\n",
        "        for i in range(opts.n_attributes):\n",
        "            probs.append(probs_by_att)\n",
        "\n",
        "    if opts.probs==\"entropy_test\":\n",
        "        probs=[]\n",
        "        for i in range(opts.n_attributes):\n",
        "            probs_by_att = np.ones(opts.n_values)\n",
        "            probs_by_att[0]=1+(1*i)\n",
        "            probs_by_att /= probs_by_att.sum()\n",
        "            probs.append(probs_by_att)\n",
        "\n",
        "    if opts.probs_attributes==\"uniform\":\n",
        "        probs_attributes=[1]*opts.n_attributes\n",
        "\n",
        "    if opts.probs_attributes==\"uniform_indep\":\n",
        "        probs_attributes=[]\n",
        "        probs_attributes=[0.2]*opts.n_attributes\n",
        "\n",
        "    if opts.probs_attributes==\"echelon\":\n",
        "        probs_attributes=[]\n",
        "        for i in range(opts.n_attributes):\n",
        "            #probs_attributes.append(1.-(0.2)*i)\n",
        "            #probs_attributes.append(0.7+0.3/(i+1))\n",
        "            probs_attributes=[1.,0.95,0.9,0.85]\n",
        "\n",
        "    if opts.custom_dist:\n",
        "        train_loader = DistributionLoader(n_features=opts.n_values, batch_size=opts.batch_size,batches_per_epoch=opts.batches_per_epoch)\n",
        "        #OneHotLoaderCompositionality\n",
        "        # single batches with 1s on the diag\n",
        "        test_loader = DistributionUniformLoader(n_features=opts.n_values)\n",
        "    else:\n",
        "        #TestLoaderCompositionality\n",
        "        train_loader = OneHotLoaderCompositionality(n_values=opts.n_values, n_attributes=opts.n_attributes, batch_size=opts.batch_size*opts.n_attributes,\n",
        "                                                    batches_per_epoch=opts.batches_per_epoch, probs=probs, probs_attributes=probs_attributes)\n",
        "\n",
        "        # single batches with 1s on the diag\n",
        "        test_loader = TestLoaderCompositionality(n_values=opts.n_values,n_attributes=opts.n_attributes)\n",
        "    ### SENDER ###\n",
        "\n",
        "    sender = Sender(n_features=opts.n_attributes*opts.n_values, n_hidden=opts.sender_hidden)\n",
        "\n",
        "    sender = core.RnnSenderReinforce(sender,opts.vocab_size, opts.sender_embedding, opts.sender_hidden,\n",
        "                                    cell=opts.sender_cell, max_len=opts.max_len, num_layers=opts.sender_num_layers,\n",
        "                                    force_eos=force_eos)\n",
        "\n",
        "    sender.load_state_dict(torch.load(opts.checkpoint_path))\n",
        "    for p in sender.parameters():\n",
        "        p.requires_grad = False\n",
        "    ### RECEIVER ###\n",
        "\n",
        "    receiver = Receiver(n_features=opts.n_values, n_hidden=opts.receiver_hidden)\n",
        "\n",
        "    if not opts.impatient:\n",
        "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
        "        receiver = RnnReceiverCompositionality(receiver, opts.vocab_size, opts.receiver_embedding,\n",
        "                                            opts.receiver_hidden, cell=opts.receiver_cell,\n",
        "                                            num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_attributes=opts.n_attributes, n_values=opts.n_values)\n",
        "    else:\n",
        "        receiver = Receiver(n_features=opts.receiver_hidden, n_hidden=opts.vocab_size)\n",
        "        # If impatient 1\n",
        "        receiver = RnnReceiverImpatientCompositionality(receiver, opts.vocab_size, opts.receiver_embedding,\n",
        "                                            opts.receiver_hidden, cell=opts.receiver_cell,\n",
        "                                            num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_attributes=opts.n_attributes, n_values=opts.n_values)\n",
        "\n",
        "\n",
        "    if not opts.impatient:\n",
        "        game = CompositionalitySenderReceiverRnnReinforce(sender, receiver, loss_compositionality, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
        "                                            n_attributes=opts.n_attributes,n_values=opts.n_values,receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
        "                                            length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen,reg=opts.reg)\n",
        "    else:\n",
        "        game = CompositionalitySenderImpatientReceiverRnnReinforce(sender, receiver, loss_impatient_compositionality, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
        "                                            n_attributes=opts.n_attributes,n_values=opts.n_values,att_weights=opts.att_weights,receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
        "                                            length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen,reg=opts.reg)\n",
        "\n",
        "\n",
        "    optimizer = opts.optimizer_class(game.parameters(),lr=opts.lr)\n",
        "\n",
        "    trainer = CompoTrainer(n_attributes=opts.n_attributes,n_values=opts.n_values,game=game, optimizer=optimizer, train_data=train_loader,\n",
        "                            validation_data=test_loader, callbacks=[EarlyStopperAccuracy(opts.early_stopping_thr)])\n",
        "\n",
        "    curr_accs=[0]*7\n",
        "\n",
        "    game.att_weights=[1]*(game.n_attributes)\n",
        "\n",
        "    accs = []\n",
        "\n",
        "    for epoch in range(int(opts.n_epochs)):\n",
        "\n",
        "        if epoch%50==0:\n",
        "          print(\"Epoch: \"+str(epoch))\n",
        "\n",
        "        with HiddenPrints():\n",
        "            trainer.train(n_epochs=1)\n",
        "        if not opts.impatient:\n",
        "            if opts.custom_dist:\n",
        "                acc_vec,messages=custom_dump_compositionality(trainer.game, opts.n_attributes, opts.n_values, device, False,epoch)\n",
        "            else:\n",
        "                acc_vec,messages=dump_compositionality(trainer.game, opts.n_attributes, opts.n_values, device, False,epoch)\n",
        "        else:\n",
        "            if opts.custom_dist:\n",
        "                acc_vec,messages=custom_dump_impatient_compositionality(trainer.game, opts.n_attributes, opts.n_values, device, False,epoch)\n",
        "            else:\n",
        "                acc_vec,messages=dump_impatient_compositionality(trainer.game, opts.n_attributes, opts.n_values, device, False,epoch)\n",
        "\n",
        "        # ADDITION TO SAVE MESSAGES\n",
        "        #print(acc_vec.T)\n",
        "        accs.append(np.mean(acc_vec))\n",
        "\n",
        "    metric_vals = None\n",
        "    if opts.compute_metrics:\n",
        "      #Create dataset for metric computation\n",
        "      if opts.custom_dist:\n",
        "          #Dataset creation\n",
        "          idxs = np.arange(len(distribution))\n",
        "          batch_data = np.zeros((len(distribution),opts.n_values*2,))\n",
        "          for i in range(distribution_lbl.shape[1]):\n",
        "              batch_data[np.arange(len(distribution)),distribution_lbl[idxs,i]+i*opts.n_values] = 1\n",
        "          dataset = torch.from_numpy(batch_data).float()\n",
        "      else:\n",
        "          l = []\n",
        "          c = 0\n",
        "          data = next(iter(test_loader))[0]\n",
        "          for idx,i in enumerate(data):\n",
        "              c += 1\n",
        "              if idx < 1000:\n",
        "                  l.append(i[None])\n",
        "          dataset = torch.cat(l,axis=0)\n",
        "          print(\"metric dataset\",dataset.shape)\n",
        "\n",
        "      metric = Metrics(dataset, opts.device, opts.n_attributes, opts.n_values, opts.vocab_size, freq=20)\n",
        "      metric.trainer = trainer\n",
        "      metric_vals = metric.dump_stats()\n",
        "\n",
        "    core.close()\n",
        "\n",
        "    return accs,metric_vals\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "9mZvCsgPs0cA",
        "outputId": "e70be08f-c921-4092-a7e3-06ef2d3a7d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "--- 0\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/egg/core/util.py:847: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  eos_positions = (message[i, :] == 0).nonzero()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50\n",
            "Epoch: 100\n",
            "metric dataset torch.Size([1000, 200])\n",
            "{\"epoch\": 0, \"positional_disent\": 0.9702141284942627, \"bag_of_symbol_disent\": 0.9445710182189941, \"topographic_sim\": 0.9729554940844154}\n",
            "0.93505\n",
            "Epoch: 0\n",
            "Epoch: 50\n",
            "Epoch: 100\n",
            "0.93505\n",
            "Epoch: 0\n",
            "Epoch: 50\n",
            "Epoch: 100\n",
            "0.9349\n",
            "--- 1\n",
            "Epoch: 0\n",
            "Epoch: 50\n",
            "Epoch: 100\n",
            "metric dataset torch.Size([1000, 200])\n",
            "{\"epoch\": 0, \"positional_disent\": 0.9960936307907104, \"bag_of_symbol_disent\": 0.9553039073944092, \"topographic_sim\": 0.9956404687760368}\n",
            "0.93145\n",
            "Epoch: 0\n",
            "Epoch: 50\n",
            "Epoch: 100\n",
            "0.9316\n",
            "Epoch: 0\n",
            "Epoch: 50\n",
            "Epoch: 100\n",
            "0.93165\n",
            "--- 2\n",
            "Epoch: 0\n",
            "Epoch: 50\n",
            "Epoch: 100\n",
            "metric dataset torch.Size([1000, 200])\n",
            "{\"epoch\": 0, \"positional_disent\": 0.9936408996582031, \"bag_of_symbol_disent\": 0.9490382671356201, \"topographic_sim\": 0.9906570885661963}\n",
            "0.94505\n",
            "Epoch: 0\n",
            "Epoch: 50\n",
            "Epoch: 100\n",
            "0.9451\n",
            "Epoch: 0\n",
            "Epoch: 50\n",
            "Epoch: 100\n",
            "0.945\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d063e42e-3fa4-49f5-a742-a6af328d2c52\", \"datastd.p\", 28021)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "opts = Config()\n",
        "data = []\n",
        "for i,f in enumerate(os.listdir(opts.checkpoint_path)):\n",
        "    print('---',i)\n",
        "    data.append([])\n",
        "    for j in range(opts.nb_children_per_language):#68\n",
        "        opts = Config()\n",
        "        opts.nb_children_per_language = 3\n",
        "        #opts.n_epochs = 1\n",
        "        opts.checkpoint_path += \"/\"+f\n",
        "        opts.compute_metrics = j==0\n",
        "        accs,metrics_val = train_config(opts)\n",
        "        data[i].append([accs,metrics_val])\n",
        "        print(accs[-1])\n",
        "\n",
        "import pickle\n",
        "with open('datastd.p','wb') as f:\n",
        "    pickle.dump(data,f)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"datastd.p\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-8az3Nb6XjT"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwqu0B4W72O1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyeA1vI87vTU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cb84304a-8207-44b4-add5-67b7998b2087"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-77576bda4dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data(4).p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data(4).p'"
          ]
        }
      ],
      "source": [
        "with open('data(4).p','rb') as  f:\n",
        "    data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EgOlF356Zq0"
      },
      "outputs": [],
      "source": [
        "compo_scores = []\n",
        "learn_scores_mean = []\n",
        "learn_scores_var = []\n",
        "for d in data:\n",
        "    compo_scores.append([d[0][1]['positional_disent'],d[0][1]['bag_of_symbol_disent'],d[0][1]['topographic_sim']])\n",
        "    learn_scores_mean.append(np.mean([np.sum(d[i][0]) for i in range(len(d))]))\n",
        "    learn_scores_var.append(np.var([np.sum(d[i][0]) for i in range(len(d))]))\n",
        "\n",
        "compo_scores = np.array(compo_scores)\n",
        "learn_scores_mean = np.array(learn_scores_mean)\n",
        "learn_scores_var = np.array(learn_scores_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpEpb04q7ydC"
      },
      "outputs": [],
      "source": [
        "learn_scores_mean = (learn_scores_mean-learn_scores_mean.mean())/learn_scores_mean.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjYRY5XN75ns"
      },
      "outputs": [],
      "source": [
        "learn_scores_mean = (learn_scores_mean-learn_scores_mean.min())/(learn_scores_mean.max()-learn_scores_mean.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GzJ2EQl6LGF"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4z9A7MCXS-i"
      },
      "outputs": [],
      "source": [
        "for i in range(len(compo_scores)):\n",
        "    print(compo_scores[i],learn_scores_mean[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB-5Kqqn6KQs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "\n",
        "cmap = cmap = matplotlib.cm.get_cmap('jet')\n",
        "\n",
        "for i in range(len(compo_scores)):\n",
        "    color = cmap(learn_scores_mean[i])\n",
        "    ax.scatter(*compo_scores[i],c=color)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NlBJZf866mJ8",
        "5w2khG5Q2vkr",
        "DpFDy2Fw6prA"
      ],
      "name": "LazImpaCompoChild1000Std.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}